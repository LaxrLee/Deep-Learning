{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import nd\n",
    "from mxnet.gluon import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense(None -> 2, linear)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dense layer with two output units\n",
    "layer = nn.Dense(2)\n",
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize its weights with the default initialization method, which draws random values uniformly from [-0.7,0.7]\n",
    "layer.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.00986117 -0.04696713]\n",
       " [-0.00033285 -0.03279176]\n",
       " [-0.00225417 -0.05342289]]\n",
       "<NDArray 3x2 @cpu(0)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Forward pass with random data. We create a (3,4)shape random x and feed into the layer to compute the output\n",
    "x = nd.random.uniform(-1,1,(3,4))\n",
    "layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.00952624 -0.01501013  0.05958354  0.04705103]\n",
       " [-0.06005495 -0.02276454 -0.0578019   0.02074406]]\n",
       "<NDArray 2x4 @cpu(0)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Access weight\n",
    "layer.weight.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2D(None -> 6, kernel_size=(5, 5), stride=(1, 1), Activation(relu))\n",
       "  (1): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False, global_pool=False, pool_type=max, layout=NCHW)\n",
       "  (2): Conv2D(None -> 16, kernel_size=(3, 3), stride=(1, 1), Activation(relu))\n",
       "  (3): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False, global_pool=False, pool_type=max, layout=NCHW)\n",
       "  (4): Dense(None -> 120, Activation(relu))\n",
       "  (5): Dense(None -> 84, Activation(relu))\n",
       "  (6): Dense(None -> 10, linear)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chain layers into a neural network\n",
    "#During forward pass, we run layers sequentially one by one. The following code implements a famous network called LeNet through nn .Sequential\n",
    "net  = nn.Sequential()\n",
    "#Add a sequence of layers\n",
    "net.add(#similar to dense, it is not necessarily to identify the input channels\n",
    "nn.Conv2D(channels=6, kernel_size=5, activation = 'relu'),\n",
    "#One can also use a tuple to specify non-symmetric pool and stride sizes\n",
    "nn.MaxPool2D(pool_size=2, strides=2),\n",
    "nn.Conv2D(channels=16, kernel_size=3, activation='relu'),\n",
    "nn.MaxPool2D(pool_size=2, strides=2),\n",
    "    #The dense layer will automatically reshape the 4-D output of the last\n",
    "    #Max pooling layer into the 2-D shape: (x.shape[0], x.size/x.shape[0])\n",
    "nn.Dense(120, activation = \"relu\"),\n",
    "nn.Dense(84, activation = \"relu\"),\n",
    "nn.Dense(10))\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.initialize()\n",
    "#Input shape is(batch_size, color_channels, height, width)\n",
    "x = nd.random.uniform(shape = (4,1,28,28))\n",
    "y = net(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 1, 5, 5), (84,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net[0].weight.data().shape, net[5].bias.data().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MixMLP(\n",
       "  (blk): Sequential(\n",
       "    (0): Dense(None -> 3, Activation(relu))\n",
       "    (1): Dense(None -> 4, Activation(relu))\n",
       "  )\n",
       "  (dense): Dense(None -> 5, linear)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create A Neural Network Flexibly\n",
    "class MixMLP(nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        # Run `nn.Block`'s init method\n",
    "        super(MixMLP, self).__init__(**kwargs)\n",
    "        self.blk = nn.Sequential()\n",
    "        self.blk.add(nn.Dense(3, activation='relu'),\n",
    "                     nn.Dense(4, activation='relu'))\n",
    "        self.dense = nn.Dense(5)\n",
    "    def forward(self, x):\n",
    "        y = nd.relu(self.blk(x))\n",
    "        print(y)\n",
    "        return self.dense(y)\n",
    "\n",
    "net = MixMLP()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[0.0000000e+00 0.0000000e+00 2.1124955e-05 6.4140237e-05]\n",
      " [0.0000000e+00 0.0000000e+00 2.2888425e-04 5.9812429e-04]]\n",
      "<NDArray 2x4 @cpu(0)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 1.1762700e-06  4.1317876e-06 -3.8491830e-06  3.0992901e-06\n",
       "  -1.3130854e-06]\n",
       " [ 1.3158093e-05  3.9258037e-05 -3.8034632e-05  2.8098166e-05\n",
       "  -1.1850577e-05]]\n",
       "<NDArray 2x5 @cpu(0)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.initialize()\n",
    "x = nd.random.uniform(shape=(2,2))\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[-0.04485548  0.00594983 -0.06654498]\n",
       " [ 0.04964591 -0.06058505  0.03413684]\n",
       " [ 0.02511498 -0.00299651 -0.00648244]\n",
       " [ 0.02479142  0.00512109  0.01498631]]\n",
       "<NDArray 4x3 @cpu(0)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Access a particular weight class\n",
    "net.blk[1].weight.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
